# -*- coding: utf-8 -*-
"""Demographics-model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RePcQqBl_qPlam9rfdB2h1cpUC08I1oE
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import tensorflow as tf

data_url = "https://drive.google.com/uc?export=download&id=1p7Jsds-nex-vASgYbB3wbpCZaIG1515D"
df = pd.read_csv(data_url)
df.head()

df.shape

df.columns

#checking null values
df.isna().sum()

#unique values
df.nunique()

df.dtypes
#types of data

string_columns = df.select_dtypes(include=['object'])
string_columns.head()

df['Region, subregion, country or area *'].unique()

df['Region, subregion, country or area *'].value_counts()

updated_df = df.drop('Region, subregion, country or area *', axis=1)
updated_df.head()

updated_df.columns

updated_df['ISO3 Alpha-code'].unique()

updated_df = updated_df.drop('ISO3 Alpha-code', axis=1)
updated_df.head()

updated_df['ISO2 Alpha-code'].unique()

updated_df = updated_df.drop('ISO2 Alpha-code', axis=1)

updated_df['Type'].unique()

updated_df = updated_df.drop('Type', axis=1)

updated_df['indicator'].unique()

updated_df['indicator'].value_counts()

updated_df = updated_df.drop('indicator', axis=1)

updated_df['gender'].unique()

updated_df['gender'].value_counts()

type_variables = pd.get_dummies(updated_df['gender'], dtype=int)
type_variables.head()

updated_df = pd.concat([updated_df, type_variables], axis=1)
updated_df.head()

updated_df = updated_df.drop('gender', axis=1)
updated_df.head()

updated_df['ages'].unique()

updated_df['ages'].value_counts()

type_variables = pd.get_dummies(updated_df['ages'], dtype=int)
type_variables.head()

updated_df = pd.concat([updated_df, type_variables], axis=1)
updated_df.head()

updated_df = updated_df.drop('ages', axis=1)
updated_df.head()

"""# **Model Implementation**"""

data = updated_df

X = data.drop('non-zero-year-columns', axis=1)
y = data['non-zero-year-columns']

print(X.columns)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=24)

X_train.shape, X_test.shape, y_train.shape, y_test.shape

print(X_train.dtypes)

model = tf.keras.Sequential([
    tf.keras.layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],)),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='sigmoid'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(16, activation='relu'),
    tf.keras.layers.Dense(1)
])

# Compile the model
model.compile(
    loss = tf.keras.losses.mae,
    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),
    metrics = ['accuracy']
)

lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.01 * 0.95 ** epoch)

epoch_number = 100

# Train the model
history = model.fit(X_train, y_train,
          epochs=epoch_number,
          batch_size=32,
          validation_data=(X_test, y_test),
          callbacks=[lr_schedule])

model.summary()

y_prediction = model.predict(X_test)
y_prediction[:5]

y_test.head()

x_train_feature = X_train.values[:, 0]
x_test_feature = X_test.values[:, 0]

y_prediction = y_prediction.flatten() if len(y_prediction.shape) > 1 else y_prediction

# Plot
plt.figure(figsize=(10, 6))

plt.scatter(x_test_feature, y_test, c='g', label='Testing Data')
plt.scatter(x_test_feature, y_prediction, c='r', label='Predictions')
plt.xlabel("Feature (First Column)")
plt.ylabel("Rainfall")
plt.legend()
plt.title("Training, Testing, and Prediction Data Visualization")
plt.show()

# Create a MeanAbsoluteError instance
mae_metric = tf.keras.losses.MeanAbsoluteError()

# Calculate MAE
mae_value = mae_metric(y_test, y_prediction).numpy()

print(f"Mean Absolute Error: {mae_value}")

mse_metric = tf.keras.losses.MeanSquaredError()


mse_value = mse_metric(y_test, y_prediction).numpy()

print(f"Mean Squared Error: {mse_value}")

x_range = range(1, epoch_number+1)
loss= history.history['loss']
plt.plot(x_range, loss)
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss vs Epochs')
plt.show()

